{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/03 08:19:32 WARN Utils: Your hostname, ZenBook-win resolves to a loopback address: 127.0.1.1; using 172.18.249.83 instead (on interface eth0)\n",
      "23/03/03 08:19:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/03 08:19:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# from datetime import datetime, date\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import lit,regexp_replace, col, trim, regexp_extract\n",
    "spark = SparkSession.builder.appName(\"Masters\").getOrCreate()\n",
    "# spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "# pd.set_option('display.max_rows', 30)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', 10)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Chordata'\",\n",
       " \"'Craniata'\",\n",
       " \"'Vertebrata'\",\n",
       " \"'Chondrichthyes'\",\n",
       " \"'Elasmobranchii'\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy_excel = pd.read_excel(\"/home/rszczygielski/bioinf/magisterka/geneBank/taxonomy1.xlsx\")\n",
    "array_of_values = taxonomy_excel.values\n",
    "list_of_values = []\n",
    "for row_array in array_of_values:\n",
    "    row_array = row_array[~pd.isnull(row_array)]\n",
    "    row_list = list(row_array)\n",
    "    list_of_values.append(row_list)\n",
    "\n",
    "\n",
    "taxonomy_row_list = []\n",
    "for elem in list_of_values:\n",
    "    new_elem = list(map(str.strip, elem))\n",
    "    taxonomy_row_list.append(new_elem)\n",
    "    # print(new_elem)\n",
    "taxonomy_row_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masters = pd.read_csv(\"/home/rszczygielski/bioinf/magisterka/geneBank/results/Organisms_mitochondion_2.txt\",\\\n",
    "    header=0,\\\n",
    "    delimiter='\\t',\\\n",
    "    usecols=[\"ACCESSION\", \"ORGANISM\",\"TAXONOMY\", \"PREVIOUS_GENE\",\"CONTROL_REGION\", \"NEXT_GENE\"],\\\n",
    "    index_col=\"ACCESSION\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_info(aggragated_taxonomy, gene_column_name):\n",
    "    gen_info_list = aggragated_taxonomy[gene_column_name].unique().tolist()\n",
    "    if len(gen_info_list) == 0:\n",
    "        return \"Not found\"\n",
    "    splited_gen_info = np.char.split(gen_info_list, \" \")\n",
    "    gene_set = set()\n",
    "    specific_gene_set = set()\n",
    "    if gene_column_name == \"PREVIOUS_GENE\":\n",
    "        gene_index = 8\n",
    "    else:\n",
    "        gene_index = 0\n",
    "    for gene in splited_gen_info:\n",
    "        gene_set.add(gene[gene_index])\n",
    "        specific_gene_set.add(gene[-1])\n",
    "    joind_gene = \", \".join(list(gene_set))\n",
    "    joind_specific_gene_set = \", \".join(list(specific_gene_set))\n",
    "    return [joind_gene, joind_specific_gene_set]\n",
    "\n",
    "df_taxonomy = df_masters[[\"TAXONOMY\", \"PREVIOUS_GENE\",\"CONTROL_REGION\", \"NEXT_GENE\"]]\n",
    "\n",
    "for row_excel_taxonomy in enumerate(taxonomy_row_list):\n",
    "    joined_values_entry = \", \".join(row_excel_taxonomy[1])\n",
    "    aggragated_taxonomy = df_taxonomy.where(df_taxonomy[\"TAXONOMY\"].str.contains(joined_values_entry)).dropna()\n",
    "    # aggragated_taxonomy.to_excel(f\"/home/rszczygielski/bioinf/magisterka/geneBank/results/aggregations/{joined_values_entry}.xlsx\")\n",
    "    previos_gene = get_gene_info(aggragated_taxonomy, \"PREVIOUS_GENE\")\n",
    "    control_region = get_gene_info(aggragated_taxonomy, \"CONTROL_REGION\")\n",
    "    next_gene = get_gene_info(aggragated_taxonomy, \"NEXT_GENE\")\n",
    "    gene_info_df = pd.DataFrame(data=[[joined_values_entry, previos_gene[0], previos_gene[1], control_region[0], control_region[1], next_gene[0], next_gene[1]]],\n",
    "                                columns=[\"TAXNONOMY\", \"PREVIOUS_GENE_PRODUCT\",\"PREVIOUS_GENE_SPECIFIC_PRODUCT\",\n",
    "                                \"CONTROL_REGION_PRODUCT\", \"CONTROL_REGION_SPECIFIC_PRODUCT\", \"NEXT_GENE_PRODUCT\", \"NEXT_GENE_SPECIFIC_PRODUCT\"])\n",
    "    gene_info_df.to_excel(f\"/home/rszczygielski/bioinf/magisterka/geneBank/results/aggregations/gene_info/GENE_INFO_{joined_values_entry}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', 'tRNA', '[15535:15605](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15485:15554](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15488:15556](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15492:15562](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15486:15555](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15417:15486](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15494:15564](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15481:15550](-)', \"['tRNA-Pro']\"]\n",
      "['', '', '', '', '', '', '', '', 'tRNA', '[15482:15551](-)', \"['tRNA-Pro']\"]\n"
     ]
    }
   ],
   "source": [
    "test = \", \".join(taxonomy_row_list[6])\n",
    "aggragated_taxonomy = df_taxonomy.where(df_taxonomy[\"TAXONOMY\"].str.contains(test)).dropna()\n",
    "len(aggragated_taxonomy)\n",
    "gen_info_list = aggragated_taxonomy[\"PREVIOUS_GENE\"].unique().tolist()\n",
    "splited_gen_info = np.char.split(gen_info_list, \" \")\n",
    "gene_set = set()\n",
    "specific_gene_set = set()\n",
    "for gene in splited_gen_info:\n",
    "    print(gene)\n",
    "    gene_set.add(gene[8])\n",
    "    specific_gene_set.add(gene[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_gene_info(aggragated_taxonomy, gene_column_name):\n",
    "    gen_info_list = aggragated_taxonomy[gene_column_name].unique().tolist()\n",
    "    splited_gen_info = np.char.split(gen_info_list, \" \")\n",
    "    gene_set = set()\n",
    "    specific_gene_set = set()\n",
    "    for gene in splited_gen_info:\n",
    "        gene_set.add(gene[8])\n",
    "        specific_gene_set.add(gene[-1])\n",
    "    return gene_set, specific_gene_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_masters = spark.read.option('delimiter', '\\t').csv(\"/home/rszczygielski/bioinf/magisterka/geneBank/results/Organisms_mitochondion_1.txt\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
